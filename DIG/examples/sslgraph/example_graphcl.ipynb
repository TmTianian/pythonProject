{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of GraphCL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dig.sslgraph.utils import Encoder\n",
    "from dig.sslgraph.evaluation import GraphSemisupervised, GraphUnsupervised\n",
    "from dig.sslgraph.dataset import get_dataset\n",
    "from dig.sslgraph.method import GraphCL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Semi-supervised learning on NCI1\n",
    "\n",
    "#### Load dataset\n",
    "\n",
    "In this example, we evaluate model on NCI1 dataset in the semi-supervised setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, dataset_pretrain = get_dataset('NCI1', task='semisupervised')\n",
    "feat_dim = dataset[0].x.shape[1]\n",
    "embed_dim = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define your encoder and contrastive model (GraphCL)\n",
    "\n",
    "For semi-supervised setting, GraphCL uses ResGCN. \n",
    "\n",
    "Available augmentation includes: dropN, maskN, permE, subgraph, random[2-4]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(feat_dim, embed_dim, n_layers=3, gnn='resgcn')\n",
    "graphcl = GraphCL(embed_dim, aug_1='subgraph', aug_2='subgraph')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define evaluatior instance\n",
    "\n",
    "In this example, we use a label rate of 1%.\n",
    "\n",
    "To setup configurations (num of epochs, learning rates, etc. for pretraining and finetuning), run\n",
    "\n",
    "\n",
    "`evaluator.setup_train_config(batch_size = 128,\n",
    "    p_optim = 'Adam', p_lr = 0.0001, p_weight_decay = 0, p_epoch = 100,\n",
    "    f_optim = 'Adam', f_lr = 0.001, f_weight_decay = 0, f_epoch = 100)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = GraphSemisupervised(dataset, dataset_pretrain, label_rate=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform evaluation\n",
    "\n",
    "You can also perform evaluation with grid search on pre-training epoch and\n",
    "learning rate by running\n",
    "``\n",
    "evaluator.grid_search(learning_model=graphcl, encoder=encoder, \n",
    "    p_lr_lst=[0.1,0.01,0.001,0.0001], p_epoch_lst=[20,40,60,80,100])\n",
    "``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretraining: epoch 100: 100%|██████████| 100/100 [18:28<00:00, 11.08s/it, loss=2.447482]\n",
      "Fold 1, finetuning: 100%|██████████| 100/100 [00:12<00:00,  8.16it/s, acc=0.6399, val_loss=2.5831]\n",
      "Fold 2, finetuning: 100%|██████████| 100/100 [00:12<00:00,  7.90it/s, acc=0.6326, val_loss=12.9722]\n",
      "Fold 3, finetuning: 100%|██████████| 100/100 [00:12<00:00,  8.01it/s, acc=0.5718, val_loss=2.3225]\n",
      "Fold 4, finetuning: 100%|██████████| 100/100 [00:12<00:00,  8.08it/s, acc=0.6277, val_loss=2.9193]\n",
      "Fold 5, finetuning: 100%|██████████| 100/100 [00:12<00:00,  8.19it/s, acc=0.6229, val_loss=14.4159]\n",
      "Fold 6, finetuning: 100%|██████████| 100/100 [00:12<00:00,  7.81it/s, acc=0.6594, val_loss=1.9039]\n",
      "Fold 7, finetuning: 100%|██████████| 100/100 [00:12<00:00,  8.01it/s, acc=0.5937, val_loss=2.8002]\n",
      "Fold 8, finetuning: 100%|██████████| 100/100 [00:11<00:00,  8.37it/s, acc=0.6034, val_loss=3.4422]\n",
      "Fold 9, finetuning: 100%|██████████| 100/100 [00:12<00:00,  7.89it/s, acc=0.6180, val_loss=2.2449]\n",
      "Fold 10, finetuning: 100%|██████████| 100/100 [00:12<00:00,  7.91it/s, acc=0.5985, val_loss=2.5211]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.625547468662262, 0.04200868681073189)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(learning_model=graphcl, encoder=encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reproduce results in the paper, you may want to perform grid search and run evaluation for 5 times and take the average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Another example with a label rate of 10%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretraining: epoch 100: 100%|██████████| 100/100 [13:31<00:00,  8.12s/it, loss=2.185739]\n",
      "Fold 1, finetuning: 100%|██████████| 100/100 [00:15<00:00,  6.47it/s, acc=0.7859, val_loss=0.9314]\n",
      "Fold 2, finetuning: 100%|██████████| 100/100 [00:15<00:00,  6.54it/s, acc=0.7348, val_loss=1.5867]\n",
      "Fold 3, finetuning: 100%|██████████| 100/100 [00:15<00:00,  6.58it/s, acc=0.7226, val_loss=1.3225]\n",
      "Fold 4, finetuning: 100%|██████████| 100/100 [00:15<00:00,  6.27it/s, acc=0.7178, val_loss=1.3762]\n",
      "Fold 5, finetuning: 100%|██████████| 100/100 [00:15<00:00,  6.47it/s, acc=0.7445, val_loss=1.2206]\n",
      "Fold 6, finetuning: 100%|██████████| 100/100 [00:15<00:00,  6.36it/s, acc=0.7299, val_loss=1.3135]\n",
      "Fold 7, finetuning: 100%|██████████| 100/100 [00:16<00:00,  6.09it/s, acc=0.7056, val_loss=1.6646]\n",
      "Fold 8, finetuning: 100%|██████████| 100/100 [00:15<00:00,  6.63it/s, acc=0.6521, val_loss=1.3334]\n",
      "Fold 9, finetuning: 100%|██████████| 100/100 [00:15<00:00,  6.36it/s, acc=0.7591, val_loss=1.3038]\n",
      "Fold 10, finetuning: 100%|██████████| 100/100 [00:15<00:00,  6.49it/s, acc=0.7616, val_loss=1.4001]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7469586133956909, 0.02797759510576725)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = Encoder(feat_dim, embed_dim, n_layers=3, gnn='resgcn')\n",
    "graphcl = GraphCL(embed_dim, aug_1='random2', aug_2='random2')\n",
    "evaluator = GraphSemisupervised(dataset, dataset_pretrain, label_rate=0.1)\n",
    "evaluator.evaluate(learning_model=graphcl, encoder=encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Unsupervised representation learning\n",
    "\n",
    "#### Load dataset\n",
    "\n",
    "In this example, we evaluate model on MUTAG dataset in the unsupervised setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_dataset('MUTAG', task='unsupervised')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define your encoder and contrastive model (GraphCL)\n",
    "\n",
    "For unsupervised setting, GraphCL uses GIN with jumping knowledge (with output_dim = hidden_dim * n_layers). \n",
    "\n",
    "Available augmentation includes: dropN, maskN, permE, subgraph, random[2-4]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretraining: epoch 20: 100%|██████████| 20/20 [00:08<00:00,  2.40it/s, loss=4.617538]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch 10: acc 0.8886 +/-(0.0685)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8885964912280702, 0.06845478250921638)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_dim = 32\n",
    "encoder = Encoder(feat_dim=dataset[0].x.shape[1], hidden_dim=embed_dim, n_layers=3, gnn='gin', bn=True)\n",
    "graphcl = GraphCL(embed_dim*3, aug_1=None, aug_2='random2', tau=0.2)\n",
    "evaluator = GraphUnsupervised(dataset, log_interval=10)\n",
    "evaluator.evaluate(learning_model=graphcl, encoder=encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NCI1 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretraining: epoch 20: 100%|██████████| 20/20 [21:38<00:00, 64.94s/it, loss=1.007827] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch 10: acc 0.7779 +/-(0.0116)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7778588807785889, 0.011586664337707655)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = get_dataset('NCI1', task='unsupervised', feat_str='')\n",
    "embed_dim = 32\n",
    "encoder = Encoder(feat_dim=dataset[0].x.shape[1], hidden_dim=embed_dim, n_layers=3, gnn='gin', bn=True)\n",
    "graphcl = GraphCL(embed_dim*3, aug_1=None, aug_2='random2', tau=0.2)\n",
    "\n",
    "evaluator = GraphUnsupervised(dataset, log_interval=10)\n",
    "evaluator.evaluate(learning_model=graphcl, encoder=encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RDT-B dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretraining: epoch 20: 100%|██████████| 20/20 [14:57<00:00, 44.85s/it, loss=4.204421]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch 20: acc 0.8970 +/-(0.0247)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.897, 0.024743124746527536)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = get_dataset('REDDIT-BINARY', task='unsupervised', feat_str='')\n",
    "embed_dim = 32\n",
    "encoder = Encoder(feat_dim=dataset[0].x.shape[1], hidden_dim=embed_dim, n_layers=3, gnn='gin', bn=True)\n",
    "graphcl = GraphCL(embed_dim*3, aug_1=None, aug_2='random2', tau=0.2)\n",
    "\n",
    "evaluator = GraphUnsupervised(dataset, log_interval=10)\n",
    "evaluator.evaluate(learning_model=graphcl, encoder=encoder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
